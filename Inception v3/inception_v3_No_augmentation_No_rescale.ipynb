{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"_YeuRhJaM3O2"},"outputs":[],"source":["from __future__ import print_function, division\n","import os\n","import torch\n","import pandas as pd\n","from skimage import io, transform\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms, utils, datasets\n","import torch.nn as nn\n","from torch.nn import functional as F\n","import torch.optim as optim"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"kneGxim5M5Xg"},"outputs":[],"source":["input_path = \"../content/DATA_CHAMBER_2021/\"\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XklVl_hnNZ4e"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qMN4khQrNcrS"},"outputs":[],"source":["!unzip -uq \"/content/drive/My Drive/DATA_CHAMBER_2021.zip\" -d \"./\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8Wlreb7qNfDx"},"outputs":[],"source":["class ImageFolderWithPaths(datasets.ImageFolder):\n","\n","    # called by dataloaders\n","    def __getitem__(self, index):\n","        original_tuple = super(ImageFolderWithPaths, self).__getitem__(index)\n","        # the image file path\n","        path = self.imgs[index][0]\n","        tuple_with_path = (original_tuple + (path,))\n","        return tuple_with_path"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T-mJ7dSLNif1"},"outputs":[],"source":["preprocess = {\n","    'train':\n","    transforms.Compose([\n","        transforms.Resize(229),\n","        transforms.CenterCrop(229),\n","        # transforms.RandomHorizontalFlip(),\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","    ]),\n","    'validation':\n","    transforms.Compose([\n","        transforms.Resize(229),\n","        transforms.CenterCrop(229),\n","        # transforms.RandomHorizontalFlip(),\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","    ]),\n","}\n","\n","image_datasets = {\n","    'train': \n","    ImageFolderWithPaths(input_path + 'train', preprocess['train']),\n","    'validation': \n","    ImageFolderWithPaths(input_path + 'test', preprocess['validation'])\n","}\n","dataset_sizes = {x: len(image_datasets[x]) for x in ['train','validation']}\n","\n","dataloaders = {\n","    'train':\n","    torch.utils.data.DataLoader(image_datasets['train'],\n","                                batch_size=32,\n","                                shuffle=True,\n","                                num_workers=2, pin_memory=True),\n","    'validation':\n","    torch.utils.data.DataLoader(image_datasets['validation'],\n","                                batch_size=32,\n","                                shuffle=True,\n","                                num_workers=2, pin_memory=True)\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vCf6IAp4Nkk6"},"outputs":[],"source":["model = torch.hub.load('pytorch/vision:v0.10.0', 'inception_v3', pretrained=False)\n","model.AuxLogits.fc = nn.Linear(768, 3)\n","model.fc = nn.Linear(2048, 3)\n","# fine tuning"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ALIESf0lOUFq"},"outputs":[],"source":["import torchvision\n","from torch.autograd import Variable\n","import time\n","from PIL import Image\n","from torchvision import transforms"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8NE_fEG_OelG"},"outputs":[],"source":["criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(model.parameters(), lr=0.001,momentum=0.9)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2aX3vWMOOg3n"},"outputs":[],"source":["# t0 = time.time()\n","# print('{} seconds'.format(time.time() - t0)\n","epochLine = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ouvQxeyeOit-"},"outputs":[],"source":["def train_model(model, criterion, optimizer, num_epochs=1):\n","    train_batches = len(dataloaders['train'])\n","    lossLine = []\n","    accLine = []\n","    timeLine = []\n","    for epoch in range(num_epochs):\n","        print('-' * 40)\n","        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n","        print('-' * 20)\n","        t0 = time.time()\n","\n","        for phase in ['train']:\n","            if phase == 'train':\n","                model.train()\n","            else:\n","                model.eval()\n","\n","            training_loss = 0.0\n","            training_corrects = 0\n","\n","            for i,data in enumerate(dataloaders[phase]):\n","                inputs, labels,_ = data\n","                print(\"\\rTraining batch {}/{}\".format(i+1, train_batches), end='', flush=True)\n","                inputs = inputs.to(device)\n","                labels = labels.to(device)\n","\n","                outputs = model(inputs)\n","                loss = criterion(outputs, labels)\n","                # loss.requires_grad = True\n","\n","                if phase == 'train':\n","                    optimizer.zero_grad()\n","                    loss.backward()\n","                    optimizer.step()\n","\n","                _, preds = torch.max(outputs, 1)\n","                training_loss += loss.item() * inputs.size(0)\n","                training_corrects += torch.sum(preds == labels.data)\n","\n","            epoch_loss = training_loss / len(image_datasets[phase])\n","            lossLine.append(epoch_loss)\n","            epoch_acc = training_corrects.double() / len(image_datasets[phase])\n","            accLine.append(epoch_acc)\n","\n","            print('{} loss: {:.4f}, acc: {:.4f}'.format(phase,\n","                                                        epoch_loss,\n","                                                        epoch_acc))\n","            t1 = time.time()\n","            t = t1 - t0\n","            print('Duration :{} seconds'.format(t))\n","            ts = pd.DataFrame([t]).apply(np.float32)\n","            timeLine.append(ts)\n","    return model, lossLine, accLine, timeLine"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1JYyfEH4OniS"},"outputs":[],"source":["model = model.to(device)\n","model_trained, lossLine, accLine, timeLine = train_model(model, criterion, optimizer, num_epochs=20)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VZpjKw4TOpsq"},"outputs":[],"source":["plt.plot(epochLine, lossLine, label=\"Loss\")\n","plt.plot()\n","\n","plt.xlabel(\"Epochs\")\n","plt.ylabel(\"Loss rate\")\n","plt.title(\"Inception v3 Loss per Epoch\")\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9UyrfI3JSxL6"},"outputs":[],"source":["print(lossLine)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HMNVo97qOrmD"},"outputs":[],"source":["plt.plot(epochLine, accLine, label=\"Accuracy\")\n","plt.plot()\n","\n","plt.xlabel(\"Epochs\")\n","plt.ylabel(\"Accuracy rate\")\n","plt.title(\"Inception v3 Accurate per Epoch\")\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AILA-x_fSz4t"},"outputs":[],"source":["print(accLine)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QCmfnNQJOvAC"},"outputs":[],"source":["total_time_train = 0\n","for i in timeLine:  total_time_train += i\n","print(total_time_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dSmHI3_mOvj6"},"outputs":[],"source":["def test_model(model, criterion, optimizer):\n","    labels_input=list()\n","    labels_output=list()\n","    vid_id = list()\n","    for phase in ['validation']:\n","        model.eval()\n","\n","        for inputs, labels, fname in dataloaders[phase]:\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","            labels_input= labels_input + labels.tolist()\n","            for f in fname:\n","                vid_id.append(f.split('/')[-1].split('.')[0].split('_')[0])\n","            outputs = model(inputs)\n","            \n","            loss = criterion(outputs, labels)\n","            _, preds = torch.max(outputs, 1)\n","            \n","            labels_output= labels_output + preds.tolist()\n","    return labels_input,labels_output,vid_id\n","            \n","y_true,y_pred,vid_id = test_model(model, criterion, optimizer)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jhhv9ufbOycy"},"outputs":[],"source":["from sklearn.metrics import confusion_matrix,accuracy_score,classification_report\n","print(classification_report(y_true,y_pred))\n","accuracy_score(y_true, y_pred)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qcL36XkcO17q"},"outputs":[],"source":["df = pd.DataFrame(list(zip(y_true,y_pred,vid_id)),\n","               columns =['y_true','y_pred','vid_id'])\n","df.to_csv('df.csv',encoding='utf-8',index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZgisEmGNO4V2"},"outputs":[],"source":["vid_list = list(set(df['vid_id'].values))\n","\n","y_true = []\n","y_pred = []\n","for vid in vid_list:\n","    #print(vid)\n","    tmp_df = df[df['vid_id']==vid]\n","    #print(len(tmp_df))\n","    vid_pred = tmp_df['y_pred'].mode().values[0]\n","    vid_label = tmp_df['y_true'].mode().values[0]\n","    y_true.append(vid_label)\n","    y_pred.append(vid_pred)\n","    #print(vid_label,\"\\n\",vid_pred)\n","    \n","    print('vid: {} label: {} pred: {}'.format(vid,vid_label,vid_pred))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9McfersxO6BW"},"outputs":[],"source":["accuracy_score(y_true,y_pred)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"inception_v3_No_augmentation_No_rescale.ipynb","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}